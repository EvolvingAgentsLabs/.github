# Evolving Agents Labs

## About Our Research

A year ago, the idea of describing a workflow once to an AI and having a 2GB local model execute it daily with actual reasoning seemed like science fiction. So did generating production mobile apps with on-device AI in minutes, or having workflows that improve themselves with each execution.

We built it. We call it **LLMunix**.

We explore early-stage concepts in adaptive AI through experimental frameworks and research prototypes. Our work investigates how intelligent agents might adapt, learn, and evolveâ€”not in the cloud adapting to everyone, but locally and privately, adapting to you.

**All projects remain permanently in alpha status as ongoing research experiments.**

---

## ğŸ’­ The Vision: What If...

**What if you could describe any mobile app** â€” "personal trainer that adapts," "study assistant that quizzes me" â€” and get a working prototype with on-device AI in minutes, not months?

**What if every workflow you do more than once** becomes an agent that improves each time, learning from experience and evolving its approach?

**What if AI ran locally, privately, adapting to you** â€” not in the cloud adapting to everyone, but on your device with your data?

These are the questions driving our research. LLMunix is our experimental answer.

---

## ğŸ§ª Current Experiments

### [LLMunix](https://github.com/EvolvingAgentsLabs/llmunix) ğŸ¦„ `ALPHA`
**Pure Markdown Operating System**

A revolutionary Pure Markdown Operating System designed to be run by multiple AI runtime engines. Compatible with Claude Code, Gemini CLI, and Qwen Code.

**The Core Innovation:**
- **Define once with Claude** ($0.50): Create agent definitions with full reasoning capabilities
- **Execute infinitely with Granite** ($0): Local 2GB model executes the definition with actual reasoning
- **Cost savings**: $730/year â†’ $0.50/year for the same flexible behavior

**Key Capabilities:**
- Multi-tier memory system with short-term and long-term learning
- Dynamic agent creation during execution
- Sentient state architecture with behavioral adaptation
- Optional mobile app generation (React Native with on-device LLMs)
- Runtime engines interpret manifest files into functional operating systems

[ğŸ“– Learn More](https://evolvingagentslabs.github.io/experiments/llmunix.html) â€¢ [ğŸš€ View Project](https://github.com/EvolvingAgentsLabs/llmunix)

---

### [LLMunix Starter](https://github.com/EvolvingAgentsLabs/llmunix-starter) ğŸ­ `ALPHA`
**Pure Markdown OS Template for Claude Code Web**

A fresh LLMunix template optimized for Claude Code on the web. The factory for building specialized agents dynamicallyâ€”not pre-built solutions, just the essential kernel.

**Philosophy: The Factory, Not the Products**
- Traditional AI systems pre-define hundreds of agents for specific domains
- LLMunix Starter ships only 3 core system agents
- Creates exactly the agents you need, tailored to your specific problem
- Every project learns and improves future executions

**What You Get:**
- Essential kernel only (SystemAgent, MemoryAnalysisAgent, MemoryConsolidationAgent)
- Dynamic agent factory that creates specialized agents on demand
- Continuous learning from every execution
- Works with public and private repositories

**Use Cases:**
- Give Claude any ambitious goal
- System analyzes and creates specialized agents (VisionaryAgent, MathematicianAgent, etc.)
- Agents collaborate, produce outputs, log learnings
- Future projects bootstrap faster using past patterns

[ğŸ“– Learn More](https://evolvingagentslabs.github.io/experiments/llmunix-starter.html) â€¢ [ğŸ­ Use Template](https://github.com/EvolvingAgentsLabs/llmunix-starter)

---

### [LLMunix Marketplace](https://github.com/EvolvingAgentsLabs/llmunix-marketplace) ğŸ”Œ `ALPHA`
**Claude Code CLI Plugin**

The LLMunix kernel as a Claude Code CLI plugin. Install the Pure Markdown Operating System via the marketplace and solve complex goals with a single command.

**The `/llmunix` Command:**
```bash
/llmunix "Create a biomedical quantum computing research project"
```

**What Happens:**
1. Analyzes goal and identifies required expertise
2. Creates project structure with dedicated workspace
3. **Dynamically writes new agent markdown files** for each expertise
4. Orchestrates agent collaboration via Task tool
5. Produces outputs in project directory
6. Consolidates learnings to long-term memory
7. Future projects query and reuse successful patterns

**Installation:**
```bash
/plugin marketplace add evolving-agents-labs/llmunix-marketplace
/plugin install llmunix-plugin
/llmunix "your goal here"
```

**Core Innovation:** Instead of shipping hundreds of pre-built agents, LLMunix creates the exact agent you need with a system prompt tailored to your specific problem. A biomedical quantum computing project gets VisionaryAgent, MathematicianAgent, QuantumEngineerAgent. A web scraper gets DataExtractorAgent, ParserAgent, ValidationAgent. Exactly what you need, nothing more.

[ğŸ“– Learn More](https://evolvingagentslabs.github.io/experiments/llmunix-marketplace.html) â€¢ [ğŸ”Œ View Plugin](https://github.com/EvolvingAgentsLabs/llmunix-marketplace)

---

## ğŸ“¢ Project Evolution: From EAT to LLMunix

### Original Evolving Agents Toolkit (EAT) - Sunset Notice

The original [Evolving Agents Toolkit (EAT) Python project](https://github.com/matiasmolinas/evolving-agents) was officially discontinued in July 2025. While EAT demonstrated powerful concepts in multi-agent orchestration with MongoDB backend, we recognized the complex Python architecture was over-engineered for achieving adaptive agent behavior.

**Key insights that led to LLMunix:**
- Complex multi-component architectures created unnecessary overhead
- The core concept of autonomous agent evolution was sound
- Simpler approaches could achieve the same adaptive behaviors
- LLM capabilities alone could handle orchestration and evolution

### The Simplification

**From EAT's complexity to LLMunix's simplicity:**
- **EAT**: Multi-component Python architecture with MongoDB backend
- **LLMunix**: Pure markdown definitions interpreted by LLM runtime engines
- **Result**: Same adaptive capabilities, 10x simpler implementation

### Validation & Next Frontier

With Claude Code's implementation of **sub-agents in markdown as an official feature**, our original markdown-based agent concept has been validated by the industry. This proves the approach works.

**Our continuing research direction:**
- **LLMunix continues** as our core research platform for markdown-based agent systems
- **Three distribution methods**: Main project, Starter template, CLI plugin
- **Focus areas**: Dynamic agent creation, continuous learning, local execution
- **Next frontier**: Exploring pure LLM-native agent architectures

This represents the natural evolution: external frameworks â†’ markdown specifications â†’ LLM-native agents.

---

## ğŸ”¬ Research Areas

| Focus Area | Description |
|------------|-------------|
| **Adaptive Behavior Research** | How agents modify decision-making based on context, user sentiment, and interaction patterns |
| **Pure Markdown Architecture** | Using markdown as a complete operating system specification with clean separation of behavior, state, and execution |
| **Dynamic Agent Creation** | On-demand generation of specialized agents tailored to specific problem requirements |
| **Continuous Learning Systems** | Memory architectures enabling agents to improve through experience and pattern recognition |
| **Local-First AI Execution** | Running AI privately on-device with local models, maintaining privacy and zero marginal cost |
| **Learner-Follower Pattern** | Expensive LLMs create definitions once, edge models execute infinitely at zero cost |

---

## ğŸŒ Explore Our Research Lab

**ğŸ‘‰ [Visit evolvingagentslabs.github.io](https://evolvingagentslabs.github.io) for the complete research showcase**

### Quick Navigation
- ğŸ”¬ [View All Experiments](https://evolvingagentslabs.github.io#experiments)
- ğŸ“Š [Research Overview](https://evolvingagentslabs.github.io#about)
- ğŸ“– [LLMunix Deep Dive](https://evolvingagentslabs.github.io/experiments/llmunix.html)
- ğŸ­ [LLMunix Starter Template](https://evolvingagentslabs.github.io/experiments/llmunix-starter.html)
- ğŸ”Œ [LLMunix CLI Plugin](https://evolvingagentslabs.github.io/experiments/llmunix-marketplace.html)
- ğŸ› ï¸ [Try LLMunix](https://github.com/EvolvingAgentsLabs/llmunix#quick-start)

---

## ğŸ’¡ Real-World Applications

**What can you build with LLMunix today?**

### Workflows That Improve Themselves
- Data processing pipelines that adapt to format changes
- Research workflows that remember successful strategies
- Content generation that learns from user preferences
- Analysis tasks that evolve their approach based on results

### Mobile Apps with On-Device AI
- Personal trainers that adapt workouts to your progress (Qwen 600MB)
- Study assistants that quiz you based on your learning patterns
- Habit trackers with intelligent reminders
- Code generation apps with local AI (Granite 1.5GB)

### Privacy-First AI
- All processing happens on your device
- No data sent to external servers
- Complete control over your information
- Zero marginal cost after initial setup

**The Pattern:**
1. Describe what you want to Claude once ($0.50)
2. Get a specialized agent definition or mobile app
3. Execute locally with Granite/Qwen (free)
4. System adapts and improves with each run

---

## âš ï¸ Experimental Nature

**Important**: All our projects are research prototypes exploring early-stage concepts. They should be treated as experimental research material rather than production-ready systems.

**Current Limitations:**
- Edge models are 10-20% less accurate than Claude
- Mobile apps with LLMs are 600MB-1.5GB
- Novel tasks still require expensive LLMs
- The markdown abstraction might hit limits we haven't found

**But it's working well enough to be interesting.**

We believe in transparent, open research that advances the field through shared exploration. That's why we're sharing early and asking: Where does this break? What are we not seeing?

---

## ğŸ¤ Contributing & Feedback

We welcome researchers, developers, and curious minds to explore our work:

- **ğŸ” Explore**: Browse our experiments and documentation
- **ğŸ› Report**: Share findings, issues, or edge cases you discover
- **ğŸ’¡ Discuss**: Join conversations about adaptive agent concepts
- **ğŸ§ª Experiment**: Build upon our research prototypes
- **ğŸ¤” Challenge**: Point out architectural flaws and limitations
- **ğŸ’¬ Share**: Tell us what you'd build with local, private, adaptive AI

**Two Questions for the Community:**

1. Where does this approach break? What limitations are we not seeing?

2. If you could generate any personal AI app that runs 100% offlineâ€”what would you build?

---

## ğŸ“„ License

All projects are released under the Apache 2.0 License.

---

**Genuinely want to hear what you think. This is an experiment in seeing how far we can push edge AI + markdown definitions.**
